{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical for AI4ER. Using Machine Learning for Segmenting Mineral Phases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib qt5\n",
    "%matplotlib qt\n",
    "import hyperspy.api as hs\n",
    "import numpy as np\n",
    "from numpy import mean, std, median, sqrt, exp, log, delete\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from cycler import cycler\n",
    "\n",
    "import scipy\n",
    "from scipy import ndimage as ndi\n",
    "from scipy.stats import sem, t, norm, gaussian_kde, mstats, iqr\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "import skimage as ski\n",
    "from skimage.segmentation import random_walker\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage import exposure\n",
    "from skimage import measure\n",
    "from skimage import morphology as mph\n",
    "from skimage import restoration\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.color import rgb2gray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents <a id='link1'></a>\n",
    "\n",
    "<a href='#link2'> **1.0 Loading and Saving data**</a>\n",
    "\n",
    "<a href='#link3'> **2.0 Machine Learning for Separating Phases**</a>\n",
    "\n",
    "<a href='#link6'> **2.1 Identifying the number of phases**</a>\n",
    "\n",
    "<a href='#link7'> **2.2 Creating a phase mask**</a>\n",
    "\n",
    "<a href='#link4'> **3.0 Quantification of Phases - Mineralogy**</a>\n",
    "\n",
    "<a href='#link5'> **4.0 Quantification of Elements - Morphology**</a>\n",
    "\n",
    "This notebook contains a commented workflow on running machine learning on EDS data for phase separation and quantifying morphology. Written by Matt Ball"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Loading and Saving data <a id='link2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load in the EDS map data using the hyperspy load function and assign metadata to the object, depending on the file format of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading .bcf data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Signal2D, title: Ch 0, dimensions: (|1820, 1295)>,\n",
       " <Signal2D, title: Ch 0, dimensions: (|2000, 2000)>,\n",
       " <EDSSEMSpectrum, title: EDX, dimensions: (1820, 1295|2048)>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = hs.load('data/JM1_OL7_map1.bcf')\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = a[2]\n",
    "s.axes_manager.set_signal_dimension(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading .rpl/.raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = hs.load('your_filename.rpl').as_signal1D(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting a sub-section of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_mini = s.data[0:200,500:800,:]\n",
    "s_min = hs.signals.Signal1D(s_mini)\n",
    "s_min.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.set_signal_type(\"EDS_SEM\")\n",
    "s.axes_manager[-1].name = 'E'\n",
    "s.axes_manager['E'].units = 'keV'\n",
    "s.axes_manager['E'].scale = 0.01\n",
    "#Set the offset, the difference between the measured peak location and the true location, often an\n",
    "#artificial zero peak is added to EDS data which can be used for this. This may need to be done a few\n",
    "#times to correctly set this value\n",
    "s.axes_manager['E'].offset = 0\n",
    "#Set the beam energy to the beam energy the EDS data was collected at in keV\n",
    "s.metadata.Acquisition_instrument.SEM.beam_energy = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_min.set_signal_type(\"EDS_SEM\")\n",
    "s_min.axes_manager[-1].name = 'E'\n",
    "s_min.axes_manager['E'].units = 'keV'\n",
    "s_min.axes_manager['E'].scale = 0.01\n",
    "#Set the offset, the difference between the measured peak location and the true location, often an\n",
    "#artificial zero peak is added to EDS data which can be used for this. This may need to be done a few\n",
    "#times to correctly set this value\n",
    "s_min.axes_manager['E'].offset = -0.3\n",
    "#Set the beam energy to the beam energy the EDS data was collected at in keV\n",
    "s_min.metadata.Acquisition_instrument.SEM.beam_energy = 20\n",
    "s_min.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving data in the .hspy format (a variation on .hdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.save('your_filename')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once data has been saved as a .hspy format it can be quickly reloaded alongside all metadata previously attached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = hs.load('your_filename.hspy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href='#link1'> Return to Table of Contents</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 Machine Learning for Separating Phases <a id='link3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Identifying the number of phases <a id='link6'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we run a PCA (Principal Component Analysis) on the data to identify the number of significant principal components. The different phases will consist of both a loading map and corresponding spectrum. These can be cycled through using the arrow keys. Also plotted are two scree plots, which show the percentage of the data which can be explained by each principal component, one of which is plotted with a logarithmic y-axis, due to the large amount of data, this will be too slow to perform on the full dataset, so we will instead use the subset of data we created earlier, whilst the results of the machine learning on the full set can be loaded in and viewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b40fa8f4d7548dca7d9924528f976b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Label(value='Decomposition component index', layout=Layout(width='15%')), IntSliâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f633af5ec50>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/space/maclenna/miniconda3/lib/python3.7/site-packages/matplotlib/cbook/__init__.py\", line 216, in process\n",
      "    func(*args, **kwargs)\n",
      "  File \"/space/maclenna/miniconda3/lib/python3.7/site-packages/hyperspy/drawing/utils.py\", line 172, in function_wrapper\n",
      "    function()\n",
      "  File \"/space/maclenna/miniconda3/lib/python3.7/site-packages/hyperspy/drawing/signal1d.py\", line 145, in _on_close\n",
      "    super(Signal1DFigure, self)._on_close()\n",
      "  File \"/space/maclenna/miniconda3/lib/python3.7/site-packages/hyperspy/drawing/figure.py\", line 107, in _on_close\n",
      "    self.events.closed.trigger(obj=self)\n",
      "  File \"<string>\", line 4, in trigger\n",
      "  File \"/space/maclenna/miniconda3/lib/python3.7/site-packages/hyperspy/events.py\", line 402, in trigger\n",
      "    function(**{kw: kwargs.get(kw, None) for kw in kwsl})\n",
      "  File \"/space/maclenna/miniconda3/lib/python3.7/site-packages/hyperspy/signal.py\", line 2133, in <lambda>\n",
      "    lambda: self.events.data_changed.disconnect(self.update_plot),\n",
      "  File \"/space/maclenna/miniconda3/lib/python3.7/site-packages/hyperspy/events.py\", line 373, in disconnect\n",
      "    (function, self))\n",
      "ValueError: The <bound method BaseSignal.update_plot of <EDSSEMSpectrum, title: , dimensions: (300, 200|2048)>> function is not connected to <hyperspy.events.Event: Event that triggers when the data has changed: set()>.\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/maclenna/miniconda3/lib/python3.7/site-packages/matplotlib/cbook/__init__.py\", line 216, in process\n",
      "    func(*args, **kwargs)\n",
      "  File \"/space/maclenna/miniconda3/lib/python3.7/site-packages/hyperspy/drawing/utils.py\", line 172, in function_wrapper\n",
      "    function()\n",
      "  File \"/space/maclenna/miniconda3/lib/python3.7/site-packages/hyperspy/drawing/signal1d.py\", line 145, in _on_close\n",
      "    super(Signal1DFigure, self)._on_close()\n",
      "  File \"/space/maclenna/miniconda3/lib/python3.7/site-packages/hyperspy/drawing/figure.py\", line 107, in _on_close\n",
      "    self.events.closed.trigger(obj=self)\n",
      "  File \"<string>\", line 4, in trigger\n",
      "  File \"/space/maclenna/miniconda3/lib/python3.7/site-packages/hyperspy/events.py\", line 402, in trigger\n",
      "    function(**{kw: kwargs.get(kw, None) for kw in kwsl})\n",
      "  File \"/space/maclenna/miniconda3/lib/python3.7/site-packages/hyperspy/signal.py\", line 2133, in <lambda>\n",
      "    lambda: self.events.data_changed.disconnect(self.update_plot),\n",
      "  File \"/space/maclenna/miniconda3/lib/python3.7/site-packages/hyperspy/events.py\", line 373, in disconnect\n",
      "    (function, self))\n",
      "ValueError: The <bound method BaseSignal.update_plot of <EDSSEMSpectrum, title: , dimensions: (300, 200|2048)>> function is not connected to <hyperspy.events.Event: Event that triggers when the data has changed: set()>.\n"
     ]
    }
   ],
   "source": [
    "s_min.change_dtype('float32')\n",
    "s_min.decomposition(True, algorithm='svd', output_dimension=20)\n",
    "s_min.plot_decomposition_results()\n",
    "s_min.plot_explained_variance_ratio(log=False)\n",
    "s_min.plot_explained_variance_ratio(log=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is worth noting that the results of this PCA contain both negative loading intensities as well as negative spectra, neither of which is physically meaningful. This first step is really to identify the number of significant phases which the machine learning can pull apart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we can save the results of this analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s.learning_results.save('your_filename_PCA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's one I made earlier! Now we can load in the PCA results on the whole dataset to compare to our subsection. Alternatively we can load in results of any previous PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.learning_results.load('AI4ER_JM1_OL7_PCA.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d1b6266f9d14fd094b340a4f00060cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Label(value='Decomposition component index', layout=Layout(width='15%')), IntSliâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f61f0e60ad0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.plot_decomposition_results()\n",
    "s.plot_explained_variance_ratio(log=False)\n",
    "s.plot_explained_variance_ratio(log=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the number of principal components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of principal components can be defined either by the number which is below a critical value of variance or by the number which seem visually important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "PC = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use this number of principal components to run a non-negative matrix factorisation, a clustering algorithm which produces only positive loadings and spectra, removing the issue of non physically meaningful results. Again we will perform this only on the subset of the data and load in a previously collected result for the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "248704da4dd74a50ab4399587b7fc59a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Label(value='Decomposition component index', layout=Layout(width='15%')), IntSliâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s_min.decomposition(True, algorithm='nmf', output_dimension=PC)\n",
    "s_min.plot_decomposition_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we can save the results of this analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s.learning_results.save('your_filename_NMF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And again here's another pre-NMF-ed set of results. We could alternatively load in other previously collected results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.learning_results.load('AI4ER_JM1_OL7_NMF.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c77682104701441cadd1960f3a8c833d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Label(value='Decomposition component index', layout=Layout(width='15%')), IntSliâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s.plot_decomposition_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Creating a phase mask <a id='link7'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the results of the NMF to create phase masks which we will use to extract phase specific morphological data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmap = s.get_decomposition_loadings()\n",
    "mapsize = pmap.data.shape\n",
    "phase_map = pmap.deepcopy()\n",
    "k = pmap.deepcopy()\n",
    "k.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use an otsu filter (which finds the ideal value to separate pixels based on an assumed bimodal histogram of pixel intensities) to select pixels within each phase map which correspond to the phase rather than the background and use these to create a set of binary phase maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_otsu = np.zeros(len(phase_map), dtype='float32')\n",
    "\n",
    "for q in range (len(phase_map)):\n",
    "    phase_otsu[q-1] = ski.filters.threshold_otsu(k.inav[q-1].data)\n",
    "    phase_map.inav[q-1].data[k.inav[q-1].data < phase_otsu[q-1]] = 0\n",
    "    phase_map.inav[q-1].data[k.inav[q-1].data >= phase_otsu[q-1]] = 1\n",
    "phase_map.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then apply two filters, one to remove small objects and one to remove small holes. The filters rely on the parameter 'minsize', which is defined as the minimum number of pixels an object or hole must contain before it is considered a real feature of the mask. The next three lines may need to be run with different values of 'minsize' in order to create an adequate mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "minsize = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/space/maclenna/miniconda3/lib/python3.7/site-packages/skimage/morphology/misc.py:211: UserWarning: the min_size argument is deprecated and will be removed in 0.16. Use area_threshold instead.\n",
      "  warn(\"the min_size argument is deprecated and will be removed in \" +\n"
     ]
    }
   ],
   "source": [
    "phase_map.change_dtype('bool')\n",
    "for q in range (len(phase_map)):\n",
    "    phase = phase_map.inav[q]\n",
    "    phase.data = mph.remove_small_objects(phase.data, min_size=minsize)\n",
    "    phase_map.inav[q] = phase\n",
    "    phase1 = phase_map.inav[q]\n",
    "    phase1.data = mph.remove_small_holes(phase1.data, min_size=minsize)\n",
    "    phase_map.inav[q] = phase1\n",
    "\n",
    "mask = phase_map\n",
    "mask.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href='#link1'> Return to Table of Contents</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Quantification of Phases - Mineralogy <a id='link4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to define the mineralogy of different phases (and which phases represent distinct mineral phases) we need to sum the signal of the original data over the mineral phase masks and plot these sum spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate array with shape (4, 1295, 1820, 2048) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-afa4acc8c059>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mphase_spectrum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmapsize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmapsize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2048\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mphase_spectrum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSignal2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphase_spectrum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mphase_spectrum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_signal_dimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphase_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate array with shape (4, 1295, 1820, 2048) and data type float64"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/space/maclenna/miniconda3/lib/python3.7/site-packages/matplotlib/cbook/__init__.py\", line 216, in process\n",
      "    func(*args, **kwargs)\n",
      "  File \"/space/maclenna/miniconda3/lib/python3.7/site-packages/hyperspy/drawing/utils.py\", line 172, in function_wrapper\n",
      "    function()\n",
      "  File \"/space/maclenna/miniconda3/lib/python3.7/site-packages/hyperspy/drawing/figure.py\", line 107, in _on_close\n",
      "    self.events.closed.trigger(obj=self)\n",
      "  File \"<string>\", line 4, in trigger\n",
      "  File \"/space/maclenna/miniconda3/lib/python3.7/site-packages/hyperspy/events.py\", line 402, in trigger\n",
      "    function(**{kw: kwargs.get(kw, None) for kw in kwsl})\n",
      "  File \"/space/maclenna/miniconda3/lib/python3.7/site-packages/hyperspy/signal.py\", line 2133, in <lambda>\n",
      "    lambda: self.events.data_changed.disconnect(self.update_plot),\n",
      "  File \"/space/maclenna/miniconda3/lib/python3.7/site-packages/hyperspy/events.py\", line 373, in disconnect\n",
      "    (function, self))\n",
      "ValueError: The <bound method BaseSignal.update_plot of <Signal2D, title: Decomposition loadings of EDX, dimensions: (4|1820, 1295)>> function is not connected to <hyperspy.events.Event: Event that triggers when the data has changed: {<bound method Interactive.update of <hyperspy.interactive.Interactive object at 0x7f633a661510>>}>.\n",
      "Traceback (most recent call last):\n",
      "  File \"/space/maclenna/miniconda3/lib/python3.7/site-packages/matplotlib/cbook/__init__.py\", line 216, in process\n",
      "    func(*args, **kwargs)\n",
      "  File \"/space/maclenna/miniconda3/lib/python3.7/site-packages/hyperspy/drawing/utils.py\", line 172, in function_wrapper\n",
      "    function()\n",
      "  File \"/space/maclenna/miniconda3/lib/python3.7/site-packages/hyperspy/drawing/figure.py\", line 107, in _on_close\n",
      "    self.events.closed.trigger(obj=self)\n",
      "  File \"<string>\", line 4, in trigger\n",
      "  File \"/space/maclenna/miniconda3/lib/python3.7/site-packages/hyperspy/events.py\", line 402, in trigger\n",
      "    function(**{kw: kwargs.get(kw, None) for kw in kwsl})\n",
      "  File \"/space/maclenna/miniconda3/lib/python3.7/site-packages/hyperspy/signal.py\", line 2133, in <lambda>\n",
      "    lambda: self.events.data_changed.disconnect(self.update_plot),\n",
      "  File \"/space/maclenna/miniconda3/lib/python3.7/site-packages/hyperspy/events.py\", line 373, in disconnect\n",
      "    (function, self))\n",
      "ValueError: The <bound method BaseSignal.update_plot of <Signal2D, title: Decomposition loadings of EDX, dimensions: (4|1820, 1295)>> function is not connected to <hyperspy.events.Event: Event that triggers when the data has changed: {<bound method Interactive.update of <hyperspy.interactive.Interactive object at 0x7f633a661510>>}>.\n"
     ]
    }
   ],
   "source": [
    "phase_spectrum = np.zeros((PC,mapsize[1],mapsize[2],2048))\n",
    "phase_spectrum = hs.signals.Signal2D(phase_spectrum)\n",
    "phase_spectrum.axes_manager.set_signal_dimension(3)\n",
    "\n",
    "for q in range (len(phase_map)):\n",
    "    m = mask.inav[q]\n",
    "    m.axes_manager.set_signal_dimension(0)\n",
    "    phase_spectrum.inav[q] = m * s\n",
    "\n",
    "phase_spectrum.axes_manager.set_signal_dimension(1)\n",
    "phase_spectrum.change_dtype('float32')\n",
    "\n",
    "spectra_sum = np.zeros((len(phase_map),2048))\n",
    "for q in range(len(phase_map)):\n",
    "    spectra_sum[q-1] = phase_spectrum.inav[:,:,q-1].sum()\n",
    "\n",
    "spectra_sum = hs.signals.EDSSEMSpectrum(spectra_sum)\n",
    "spectra_sum.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now know which mineral phase masks correspond to which real mineralogy, alternatively, we could reconstruct the original data from the machine learning output to remove noise and use this for more traditional 'guesswork'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate array with shape (2048, 2356900) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-3b0b7e1bb0af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_decomposition_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/space/maclenna/miniconda3/lib/python3.7/site-packages/hyperspy/learn/mva.py\u001b[0m in \u001b[0;36mget_decomposition_model\u001b[0;34m(self, components)\u001b[0m\n\u001b[1;32m    908\u001b[0m         \"\"\"\n\u001b[1;32m    909\u001b[0m         rec = self._calculate_recmatrix(components=components,\n\u001b[0;32m--> 910\u001b[0;31m                                         mva_type='decomposition')\n\u001b[0m\u001b[1;32m    911\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mrec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/space/maclenna/miniconda3/lib/python3.7/site-packages/hyperspy/learn/mva.py\u001b[0m in \u001b[0;36m_calculate_recmatrix\u001b[0;34m(self, components, mva_type)\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0mloadings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbss_loadings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcomponents\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfactors\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mloadings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m             signal_name = 'model from %s with %i components' % (\n\u001b[1;32m    865\u001b[0m                 mva_type, factors.shape[1])\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate array with shape (2048, 2356900) and data type float64"
     ]
    }
   ],
   "source": [
    "mod = s.get_decomposition_model()\n",
    "mod.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href='#link1'> Return to Table of Contents</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 Quantification of Phases  - Morphology <a id='link5'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we define some functions for quantifying and plotting morphological data, from the 'grain_size_tools' toolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def area2diameter(areas, correct_diameter=None):\n",
    "    \"\"\" Calculate the equivalent cirular diameter from sectional areas.\n",
    "    Parameters\n",
    "    ----------\n",
    "    areas : array_like\n",
    "        the sectional areas of the grains\n",
    "    correct_diameter : None or positive scalar, optional\n",
    "        add the width of the grain boundaries to correct the diameters. If\n",
    "        correct_diameter is not declared no correction is considered.\n",
    "    Returns\n",
    "    -------\n",
    "    A numpy array with the equivalent circular diameters\n",
    "    \"\"\"\n",
    "\n",
    "    # calculate the equivalent circular diameter\n",
    "    diameters = 2 * np.sqrt(areas / np.pi)\n",
    "\n",
    "    # diameter correction adding edges (if applicable)\n",
    "    if correct_diameter is not None:\n",
    "        diameters += correct_diameter\n",
    "\n",
    "    return diameters\n",
    "\n",
    "def freq_plot(diameters, binList, xgrid, y_values, y_max, x_peak, mean_GS, median_GS, plot, gmean=None):\n",
    "    \"\"\" Generate a frequency vs grain size plot\"\"\"\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    ax.hist(diameters,\n",
    "            bins=binList,\n",
    "            range=(0, diameters.max()),\n",
    "            density=True,\n",
    "            color='#80419d',\n",
    "            edgecolor='#C59fd7',\n",
    "            alpha=0.7)\n",
    "    ax.plot([mean_GS, mean_GS], [0, y_max],\n",
    "            linestyle='-',\n",
    "            color='#2F4858',\n",
    "            label='arith. mean',\n",
    "            linewidth=2.5)\n",
    "    ax.plot([median_GS, median_GS], [0, y_max],\n",
    "            linestyle='--',\n",
    "            color='#2F4858',\n",
    "            label='median',\n",
    "            linewidth=2.5)\n",
    "\n",
    "    ax.set_ylabel('density', color='#252525')\n",
    "\n",
    "    if plot == 'linear':\n",
    "        ax.plot([gmean, gmean], [0, y_max],\n",
    "                linestyle='-',\n",
    "                color='C1',\n",
    "                label='geo. mean')\n",
    "        ax.set_xlabel(r'apparent diameter ($\\mu m$)', color='#252525')\n",
    "\n",
    "    elif plot == 'log':\n",
    "        ax.set_xlabel(r'apparent diameter $\\log_e{(\\mu m)}$', color='#252525')\n",
    "\n",
    "    elif plot == 'log10':\n",
    "        ax.set_xlabel(r'apparent diameter $\\log_{10}{(\\mu m)}$', color='#252525')\n",
    "\n",
    "    elif plot == 'norm':\n",
    "        ax.set_xlabel(r'normalized apparent diameter $\\log_e{(\\mu m)}$', color='#252525')\n",
    "\n",
    "    elif plot == 'sqrt':\n",
    "        ax.set_xlabel(r'Square root apparent diameter ($\\sqrt{\\mu m}$)', color='#252525')\n",
    "\n",
    "    ax.plot(xgrid, y_values,\n",
    "            color='#2F4858')\n",
    "\n",
    "    ax.vlines(x_peak, 0, y_max,\n",
    "              linestyle=':',\n",
    "              color='#2F4858',\n",
    "              label='kde peak',\n",
    "              linewidth=2.5)\n",
    "\n",
    "    ax.legend(loc='best', fontsize=16)\n",
    "    ax.set_ylim(bottom=-0.001)\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    return plt.show()\n",
    "\n",
    "def gen_xgrid(start, stop, precision):\n",
    "    \"\"\" Returns a mesh of values (i.e. discretize the\n",
    "    sample space) with a range and desired precision.\n",
    "    Parameters\n",
    "    ----------\n",
    "    start : scalar\n",
    "        the starting value of the sequence\n",
    "    stop : scalar\n",
    "        the end value of the sequence\n",
    "    precision : scalar\n",
    "        the desired precision (density) of the mesh\n",
    "    \"\"\"\n",
    "\n",
    "    rango = stop - start\n",
    "\n",
    "    # num = range / precision; as long as range > precision\n",
    "    if rango < precision:\n",
    "        raise ValueError('Caution! the precision must be smaller than the range of grain sizes')\n",
    "    else:\n",
    "        n = int(round(rango / precision, 0))\n",
    "\n",
    "    return np.linspace(start, stop, num=n)\n",
    "\n",
    "def calc_freq_peak(diameters, bandwidth, max_precision):\n",
    "    \"\"\" Estimate the peak of the frequency (\"mode\") of a continuous\n",
    "    distribution based on the Gaussian kernel density estimator. It\n",
    "    uses Scipy's gaussian kde method.\n",
    "    Parameters\n",
    "    ----------\n",
    "    diameters : array_like\n",
    "        the diameters of the grains\n",
    "    bandwidth : string, positive scalar or callable\n",
    "        the method to estimate the bandwidth or a scalar directly defining the\n",
    "        bandwidth. Methods can be 'silverman' or 'scott'.\n",
    "    max_precision : positive scalar\n",
    "        the maximum precision expected for the \"peak\" estimator.\n",
    "    Call functions\n",
    "    --------------\n",
    "    - gen_xgrid\n",
    "    - kde (from scipy)\n",
    "    Returns\n",
    "    -------\n",
    "    The x and y values to contruct the kde, the peak grain size,\n",
    "    the maximum density value,, and the bandwidth\n",
    "    \"\"\"\n",
    "\n",
    "    # check bandwidth and estimate Gaussian kernel density function\n",
    "    if isinstance(bandwidth, (int, float)):\n",
    "        bw = bandwidth / diameters.std(ddof=1)\n",
    "        kde = gaussian_kde(diameters, bw_method=bw)\n",
    "\n",
    "    elif isinstance(bandwidth, str):\n",
    "        kde = gaussian_kde(diameters, bw_method=bandwidth)\n",
    "        bw = round(kde.covariance_factor() * diameters.std(ddof=1), 2)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"bandwidth must be integer, float, or plug-in methods 'silverman' or 'scott'\")\n",
    "\n",
    "    # locate the peak\n",
    "    xgrid = gen_xgrid(diameters.min(), diameters.max(), max_precision)\n",
    "    densities = kde(xgrid)\n",
    "    y_max, peak_grain_size = np.max(densities), xgrid[np.argmax(densities)]\n",
    "\n",
    "    return xgrid, densities, peak_grain_size, y_max, bw\n",
    "\n",
    "\n",
    "def calc_freq_grainsize(diameters, binsize, plot, bandwidth, max_precision):\n",
    "    \"\"\" Calculate the distribution of grain sizes using the histogram and Gaussian\n",
    "    kernel density estimator (KDE). It returns the modal interval, the middle value\n",
    "    of modal interval, and the frequency peak based on the KDE, and call the\n",
    "    function responsible for generating the corresponding plot.\n",
    "    Parameters\n",
    "    ----------\n",
    "    diameters : array_like\n",
    "        the diameters of the grains\n",
    "    binsize : string (rule of thumb), or posive scalar\n",
    "        the bin size\n",
    "    plot : string\n",
    "        the type of plot and grain size, either 'linear', 'log' or 'sqrt'.\n",
    "    bandwidth : string, scalar or callable, optional\n",
    "        the method to estimate the bandwidth or a scalar directly defining the\n",
    "        bandwidth. Methods can be 'silverman' or 'scott'.\n",
    "    max_precision : positive scalar\n",
    "        the maximum precision expected for the \"peak\" kde-based estimator\n",
    "    References\n",
    "    ----------\n",
    "    Scott, D.W. (1992) Multivariate Density Estimation: Theory, Practice, and Visualization\n",
    "    Silverman, B.W. (1986) Density Estimation for Statistics and Data Analysis\n",
    "    Call functions\n",
    "    --------------\n",
    "    - freq_plot\n",
    "    - calc_freq_peak\n",
    "    \"\"\"\n",
    "\n",
    "    if len(diameters) < 433:  # TODO: Change this in next version, this is not apply for all distributions!\n",
    "        print(' ')\n",
    "        print('Caution! You should use at least 433 grain measurements for reliable results')\n",
    "\n",
    "    mean_GS, std_GS = mean(diameters), std(diameters)\n",
    "    median_GS, iqr_GS = median(diameters), iqr(diameters)\n",
    "    if plot == 'linear':\n",
    "        gmean = mstats.gmean(diameters)  # geometric mean\n",
    "        gsd = np.exp(np.std(np.log(diameters)))  # multiplicative (geometric) standard deviation\n",
    "        mean_RMS = sqrt(mean(diameters**2))  # root mean square\n",
    "\n",
    "    # estimate the number of classes using an automatic plug-in method (if apply)\n",
    "    if type(binsize) is str:\n",
    "        bin_method = binsize\n",
    "        histogram, bin_edges = np.histogram(diameters, bins=binsize, range=(diameters.min(), diameters.max()))\n",
    "        binsize = bin_edges[1] - bin_edges[0]\n",
    "    else:\n",
    "        bin_method = None\n",
    "        bin_edges = np.arange(diameters.min(), diameters.max() + binsize, binsize)\n",
    "        histogram, bin_edges = np.histogram(diameters, bins=bin_edges)\n",
    "\n",
    "    # find the grain size range in which the histogram value is maximum\n",
    "    modInt_leftEdge = bin_edges[np.argmax(histogram)]\n",
    "    modInt_rightEdge = modInt_leftEdge + binsize\n",
    "\n",
    "    # Estimate the frequency peak grain size based on kde\n",
    "    x_kde, y_kde, peak, y_max, bw = calc_freq_peak(diameters, bandwidth, max_precision)\n",
    "\n",
    "    print(' ')\n",
    "    print('CENTRAL TENDENCY ESTIMATORS')\n",
    "    print('Arithmetic mean = {} microns' .format(round(mean_GS, 2)))\n",
    "    if plot == 'linear':\n",
    "        print('Geometric mean = {} microns' .format(round(gmean, 2)))\n",
    "        print('RMS mean = {} microns (discouraged)' .format(round(mean_RMS, 2)))\n",
    "    print('Median = {} microns' .format(round(median_GS, 2)))\n",
    "    print('Peak grain size (based on KDE) = {} microns' .format(round(peak, 2)))\n",
    "\n",
    "    print(' ')\n",
    "    print('DISTRIBUTION FEATURES (SPREADING AND SHAPE)')\n",
    "    print('Standard deviation = {} (1-sigma)' .format(round(std_GS, 2)))\n",
    "    print('Interquartile range (IQR) = {}' .format(round(iqr_GS, 2)))\n",
    "    if plot == 'linear':\n",
    "        print('Multiplicative standard deviation (lognormal shape) = {}' .format(round(gsd, 2)))\n",
    "\n",
    "    print(' ')\n",
    "    print('HISTOGRAM AND KDE FEATURES')\n",
    "    print('The modal interval is {left} - {right}' .format(left=round(modInt_leftEdge, 2), right=round(modInt_rightEdge, 2)))\n",
    "    print('The number of classes are {}' .format(len(histogram)))\n",
    "    if type(bin_method) is str:\n",
    "        print('The bin size is {bin} according to the {rule} rule' .format(bin=round(binsize, 2), rule=bin_method))\n",
    "\n",
    "    if type(bandwidth) is str:\n",
    "        print('KDE bandwidth = {a} ({b} rule)' .format(a=bw, b=bandwidth))\n",
    "    else:\n",
    "        print('KDE bandwidth =', bandwidth)\n",
    "\n",
    "    if plot == 'linear':\n",
    "        print('Maximum precision of the KDE estimator =', max_precision)\n",
    "        return freq_plot(diameters, bin_edges, x_kde, y_kde, y_max, peak, mean_GS, median_GS, plot, gmean)\n",
    "    elif plot == 'log':\n",
    "        print('Maximum precision of the KDE estimator =', max_precision)\n",
    "    elif plot == 'log10':\n",
    "        print('Maximum precision of the KDE estimator =', max_precision)\n",
    "    elif plot == 'sqrt':\n",
    "        print('Maximum precision of the KDE estimator =', max_precision)\n",
    "\n",
    "    return freq_plot(diameters, bin_edges, x_kde, y_kde, y_max, peak, mean_GS, median_GS, plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting grain size distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We now seperate grains which are touching but separate from each other using a watershed algorithm and subsequently calculate the area of the separated grains and the diameter of equivalent area spheres, which are saved off in .txt files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask.change_dtype('int')\n",
    "for q in range(PC):\n",
    "    distance = ndi.distance_transform_edt(mask.data[q])\n",
    "    local_maxi = peak_local_max(distance, indices=False, footprint=np.ones((3, 3)), labels=mask.data[q])\n",
    "    markers = ski.morphology.label(local_maxi)\n",
    "    labels_ws = ski.morphology.watershed(-distance, markers, mask=mask.data[q])\n",
    "    properties = ski.measure.regionprops(labels_ws)\n",
    "    diameters = np.asarray([prop.equivalent_diameter for prop in properties])\n",
    "    np.savetxt('AI4ER_diameters_'+str(q)+'.txt', diameters)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We can then read in the diameters of the different grains from the files and plot the distribution of grain sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diameters = np.loadtxt('AI4ER_diameters_1.txt')\n",
    "calc_freq_grainsize(diameters, binsize=0.1, plot='linear', bandwidth='silverman', max_precision=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href='#link1'> Return to Table of Contents</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
